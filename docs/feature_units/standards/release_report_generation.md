# Release Report Generation Guide
**Purpose:** Step-by-step guide for generating release build reports using documentation-driven approach.
**Related Documents:**
- [`release_report_spec.md`](./release_report_spec.md) — Report specification and rules
- [`release_report_template.md`](./release_report_template.md) — Report template with placeholders
- [`release_workflow.md`](./release_workflow.md) — Release workflow integration
- [`../../.cursor/rules/post_build_testing.md`](../../.cursor/rules/post_build_testing.md) — Post-build testing requirements

<<<<<<< Current (Your changes)
**CRITICAL REQUIREMENTS:**
- **Release reports MUST be generated immediately after all batches complete** (per `foundation/development/release_workflow.md` Step 1.4)
- **This is a REQUIRED step** - release cannot transition to `in_testing` status until report exists
- **Section 9 (Testing Guidance) is REQUIRED** and MUST include all manual test cases from `integration_tests.md`
- **Agents MUST always generate the complete release report** after completing a release build
- See `.cursor/rules/post_build_testing.md` for formatting requirements
=======
**CRITICAL:** After building a release, agents MUST always include Section 9 (Testing Guidance) with all
manual test cases from `integration_tests.md`. See `.cursor/rules/post_build_testing.md` for requirements.
>>>>>>> Incoming (Background Agent changes)
## Overview

Release reports are generated by following documented instructions, not by executing scripts. This ensures:

- **Transparency:** All generation logic is visible in documentation
- **Flexibility:** Easy to modify report structure without code changes
- **Agent-readability:** Agents can follow instructions to generate reports
- **Version control:** Report structure changes are tracked in git
## Quick Start

To generate a report for release `v0.1.0`:

1. Read this guide
2. Load template: `docs/feature_units/standards/release_report_template.md`
3. Parse data: `docs/releases/in_progress/v0.1.0/status.md` and `manifest.yaml`
4. Calculate metrics per spec rules
5. Replace placeholders in template
6. Write report: `docs/releases/in_progress/v0.1.0/release_report.md`
## Step-by-Step Process
### Step 1: Load Template
Read the template file:
```
docs/feature_units/standards/release_report_template.md
```
This contains the report structure with placeholders like `{RELEASE_ID}`, `{BATCH_ROWS}`, etc.
### Step 2: Parse Data Sources
**Before parsing, verify checkpoint status:**
- Check that all checkpoints match their trigger batch completion state
- If checkpoints are incorrectly `pending`, update them first (see `.cursor/rules/checkpoint_management.md`)
- Then proceed with parsing
#### 2.1 Parse status.md
Extract from `docs/releases/in_progress/{RELEASE_ID}/status.md`:
- **Release metadata:**
  - Release ID: `- **Release ID**: \`{id}\``
  - Name: `- **Name**: {name}`
  - Status: `- **Status**: \`{status}\``
- **Batches:** Parse table under `### 2. Batch Progress`
  - Format: `| {batch_id} | {fus} | {status} |`
  - Extract: batch_id, feature unit list, status
- **Feature Units:** Parse table under `### 3. Feature Unit Status`
  - Format: `| {FU_ID} | {name} | {status} | {notes} |`
  - Extract: FU ID, name, status (remove emoji), notes
- **Checkpoints:** Parse list under `### 4. Checkpoints`
  - Format: `- **{name}**: \`{status}\``
  - Extract: checkpoint name, status
- **Integration Tests:** Parse table under `### 5. Integration Test Status`
  - Format: `| {TEST_ID} | {name} | {status} |`
  - Extract: test ID, name, status
  - Also load `integration_tests.md` to get detailed test definitions (goal, steps, expected results, FUs involved)
#### 2.2 Parse integration_tests.md
Load `docs/releases/in_progress/{RELEASE_ID}/integration_tests.md` to extract:
- **Test definitions:** For each test (#### IT-XXX: Test Name):
  - Test ID, name, goal
  - Steps (convert to user-facing actions)
  - Expected results
  - Manual validation requirements (from Section 5 if present)
- **Format steps as user actions:**
  - "Call MCP `upload_file` action" → "Upload file via MCP `upload_file` action"
  - "Query events via graph" → "Query events using MCP actions or database queries"
  - Technical commands → User-friendly descriptions
- **Decisions:** Parse table under `### 6. Decision Log`
  - Format: `| {date} | {decision} | {rationale} |`
  - Extract: date, decision, rationale
#### 2.2 Parse manifest.yaml (optional)
Load `docs/releases/in_progress/{RELEASE_ID}/manifest.yaml` for reference (not strictly required for
report generation).
### Step 3: Calculate Metrics
Apply calculation rules from `release_report_spec.md` Section 3:
#### 3.1 Counts
- `totalBatches` = number of batches
- `completedBatches` = batches where status contains "Complete"
- `totalFUs` = number of feature units
- `completedFUs` = FUs where status contains "Complete"
- `partialFUs` = FUs where status contains "Partial"
- `failedFUs` = FUs where status contains "Failed" or "Not Started"
- `completedCheckpoints` = checkpoints where status is "completed"
- `totalCheckpoints` = number of checkpoints
- `completedTests` = tests where status is "passed" or "completed"
- `totalTests` = number of integration tests
#### 3.2 Percentages
- `batchCompletion` = `(completedBatches / totalBatches) * 100` (1 decimal)
- `fuCompletion` = `(completedFUs / totalFUs) * 100` (1 decimal)
- `checkpointCompletion` = `(completedCheckpoints / totalCheckpoints) * 100` (1 decimal)
- `testPassRate` = `(completedTests / totalTests) * 100` (1 decimal)
- `partialRate` = `(partialFUs / totalFUs) * 100` (1 decimal)
- `failureRate` = `(failedFUs / totalFUs) * 100` (1 decimal)
#### 3.3 Status Icon
- If status is "ready_for_deployment" or "completed": `✅`
- Otherwise: `⚠️`
### Step 4: Format Content Sections
#### 4.1 Batch Rows
For each batch, generate:
```markdown
| {batch_id} | {fus} | {status} | {icon} |
```
Icon logic:
- Status contains "Complete" → ✅
- Status contains "Partial" → ⚠️
- Otherwise → ❌
#### 4.2 FU Rows
For each feature unit, generate:
```markdown
| {FU_ID} | {FU_NAME} | {ICON} {STATUS} | {NOTES} |
```
Icon logic:
- Status contains "Complete" → ✅
- Status contains "Partial" → ⚠️
- Otherwise → ❌
Notes: Use "-" if empty
#### 4.3 Checkpoint Items
For each checkpoint, generate:
```markdown
- {ICON} **{CHECKPOINT_NAME}**: `{STATUS}`
```
Icon logic:
- Status is "completed" → ✅
- Status is "pending" → ⏳
- Otherwise → ❌
#### 4.4 Test Table
If tests exist, generate:
```markdown
| Test ID | Name | Status | FUs Tested | Description |
| ------- | ---- | ------ | ---------- | ----------- |
{TEST_ROWS}
```
For each test:
```markdown
| {TEST_ID} | {TEST_NAME} | {ICON} {STATUS} | {FUS_TESTED} | {DESCRIPTION} |
```
Icon logic:
- Status is "passed" or "completed" → ✅
- Status is "failed" → ❌
- Otherwise → ⏳
**FUs Tested:** Extract from integration_tests.md "FUs Involved" column
**Description:** Extract goal/description from integration_tests.md test definition
If no tests: `"No integration tests defined"`
#### 4.4.1 Test Case Details
For each test in integration_tests.md, generate detailed test case:
```markdown
#### {TEST_ID}: {TEST_NAME}
**Goal:** {GOAL}
**Test Steps:**
{TEST_STEPS}
**Expected Results:**
{EXPECTED_RESULTS}
**Status:** {ICON} {STATUS}
```
Extract from integration_tests.md:
- **Goal:** From "Goal:" line in test definition
- **Test Steps:** From "Steps:" section (numbered list)
- **Expected Results:** From "Expected Results:" section
- **Status:** From status.md integration test status
#### 4.5 Completed FUs Section
If `completedFUs > 0`:
```markdown
### Completed Feature Units
{FU_LIST}
```
FU list items:
```markdown
- ✅ **{FU_ID}**: {FU_NAME}{NOTES}
```
Notes: Include in parentheses if present, e.g., ` (Rule-based extraction implemented)`
#### 4.6 FU Category Sections
**Infrastructure FUs:**
Filter FUs where ID is in: FU-000, FU-002, FU-050, FU-051, FU-052, FU-053, FU-054
And status contains "Complete"
Format: `- ✅ {FU_NAME}`
**Core Services FUs:**
Filter FUs where ID is in: FU-100, FU-101, FU-102, FU-103, FU-105
And status contains "Complete"
Format: `- ✅ {FU_NAME}`
**MCP Actions FUs:**
Filter FUs where ID is in: FU-200, FU-201, FU-202, FU-203, FU-204, FU-205, FU-206, FU-061
And status contains "Complete"
Format: `- ✅ {FU_NAME}`
If no FUs in category: `"- No {category} FUs completed"`
#### 4.7 Issues Sections
**Partial FUs Section:**
If `partialFUs > 0`:
```markdown
### Partial Feature Units Requiring Follow-up
{FU_LIST}
```
FU list items:
```markdown
- ⚠️ **{FU_ID}**: {FU_NAME}
  - {NOTES}
```
**Failed FUs Section:**
If `failedFUs > 0`:
```markdown
### Failed or Not Started Feature Units
{FU_LIST}
```
FU list items:
```markdown
- ❌ **{FU_ID}**: {FU_NAME}
  - {NOTES}
```
**Failed Tests Section:**
If failed tests exist:
```markdown
### Failed Integration Tests
{TEST_LIST}
```
Test list items:
```markdown
- ❌ **{TEST_ID}**: {TEST_NAME}
```
#### 4.8 Decision Table
If decisions exist:
```markdown
| Date | Decision | Rationale |
| ---- | -------- | --------- |
{DECISION_ROWS}
```
Decision rows:
```markdown
| {DATE} | {DECISION} | {RATIONALE} |
```
If no decisions: `"No decisions recorded during this release"`
#### 4.9 Next Steps Section
Based on release status:
**If status is "ready_for_deployment":**

```markdown
### Ready for Deployment

✅ Release is ready for deployment. Recommended next steps:

1. **Pre-Release Validation:**
   
   **Required Checklist (MUST complete before testing):**
   - Run comprehensive pre-release validation checklist from `docs/developer/pre_release_checklist.md`
   - Verify TypeScript compilation passes (`npm run type-check`)
   - Verify all migrations created and applied (`npm run migrate`)
   - Verify MCP server startup (`npm run dev`)
   - Verify no stdout pollution in MCP mode
   - Run schema advisor checks (`npm run check:advisors`)
   
2. **Test Built Feature Units:**
   
   **Integration Tests (Required):**
   - Run full integration test suite from `docs/releases/in_progress/{RELEASE_ID}/integration_tests.md`
   - Execute all integration tests listed in integration_tests.md
   - Reference specific test IDs and their associated FUs
   
   **Test Commands:**
   - List test commands from integration_tests.md or acceptance_criteria.md
   - Include npm test commands for each test suite
   
   **Manual Validation (Required):**
   - List manual validation steps from integration_tests.md (e.g., Cursor/ChatGPT integration)
   
   **Acceptance Criteria Validation:**
   - Verify all product acceptance criteria from release_plan.md
   - Verify all technical acceptance criteria from release_plan.md
   - Run acceptance criteria tests

3. **Final Review:** Conduct final code review and acceptance criteria validation

4. **Deployment:** Deploy to target environment (internal validation)

5. **Monitoring:** Set up monitoring and observability for post-deployment validation

6. **Documentation:** Update deployment documentation and runbooks
```
**Note:** The testing guidance section should be generated by:

1. Reading `integration_tests.md` to extract test definitions
2. Reading `acceptance_criteria.md` or `release_plan.md` for acceptance criteria
3. Formatting test commands and manual validation steps
4. Including references to specific FUs tested by each integration test
**If status is "completed":**

```markdown
### Release Completed

✅ Release has been completed and deployed. Recommended next steps:

1. **Post-Deployment Validation:** Validate all acceptance criteria in production

2. **Monitoring:** Monitor key metrics and system health

3. **Documentation:** Update user documentation and API references

4. **Retrospective:** Conduct release retrospective to capture learnings

5. **Next Release Planning:** Begin planning for next release cycle
```
**Otherwise:**

```markdown
### In Progress

⚠️ Release is still in progress. Recommended next steps:

1. **Complete Remaining FUs:** Focus on completing {REMAINING_COUNT} remaining Feature Unit(s)

2. **Integration Testing:** Run integration tests for completed batches

3. **Checkpoint Reviews:** Complete pending checkpoint reviews

4. **Issue Resolution:** Address any blockers or partial implementations
```
#### 4.10 Conditional Warnings
Generate warnings section if applicable:
If `partialFUs > 0`:
```markdown
⚠️ **Warning:** {partialFUs} Feature Unit(s) marked as partial and may require follow-up work.
```
If `failedFUs > 0`:
```markdown
❌ **Critical:** {failedFUs} Feature Unit(s) failed or not started.
```
### Step 5: Replace Placeholders
Replace all placeholders in the template with calculated/formatted values:
- `{RELEASE_ID}` → Release ID (e.g., "v0.1.0")
- `{REPORT_DATE}` → Current date (YYYY-MM-DD)
- `{RELEASE_NAME}` → From status.md
- `{RELEASE_STATUS}` → From status.md
- `{STATUS_ICON}` → Calculated icon
- `{COMPLETED_BATCHES}` → Integer
- `{TOTAL_BATCHES}` → Integer
- `{BATCH_COMPLETION}` → Percentage (X.X%)
- `{COMPLETED_FUS}` → Integer
- `{TOTAL_FUS}` → Integer
- `{FU_COMPLETION}` → Percentage (X.X%)
- `{COMPLETED_CHECKPOINTS}` → Integer
- `{TOTAL_CHECKPOINTS}` → Integer
- `{COMPLETED_TESTS}` → Integer
- `{TOTAL_TESTS}` → Integer
- `{CONDITIONAL_WARNINGS}` → Generated warnings (or empty)
- `{BATCH_ROWS}` → Formatted batch rows
- `{PARTIAL_BATCHES}` → Integer
- `{INCOMPLETE_BATCHES}` → Integer
- `{COMPLETED_COUNT}` → Integer
- `{COMPLETED_PERCENT}` → Percentage (X.X%)
- `{PARTIAL_COUNT}` → Integer
- `{PARTIAL_PERCENT}` → Percentage (X.X%)
- `{FAILED_COUNT}` → Integer
- `{FAILED_PERCENT}` → Percentage (X.X%)
- `{TOTAL}` → Integer
- `{FU_ROWS}` → Formatted FU rows
- `{CHECKPOINT_ITEMS}` → Formatted checkpoint items
- `{TEST_TABLE}` → Formatted test table (with FUs tested and descriptions)
- `{TEST_CASE_DETAILS}` → Detailed test case sections (see Step 4.4.1)
- `{TESTING_GUIDANCE_SECTION}` → User-facing testing guidance (see Step 4.10)
- `{COMPLETED_FUS_SECTION}` → Completed FUs section (or empty)
- `{INFRASTRUCTURE_FUS}` → Infrastructure FU list
- `{CORE_SERVICES_FUS}` → Core services FU list
- `{MCP_ACTIONS_FUS}` → MCP actions FU list
- `{PARTIAL_FUS_SECTION}` → Partial FUs section (or empty)
- `{FAILED_FUS_SECTION}` → Failed FUs section (or empty)
- `{FAILED_TESTS_SECTION}` → Failed tests section (or empty)
- `{DECISION_TABLE}` → Decision table
- `{NEXT_STEPS_SECTION}` → Next steps section
- `{TESTING_GUIDANCE_SECTION}` → Testing guidance section (see Step 4.10)
- `{CHECKPOINT_COMPLETION}` → Percentage (X.X%)
- `{TEST_PASS_RATE}` → Percentage (X.X%)
- `{PARTIAL_RATE}` → Percentage (X.X%)
- `{FAILURE_RATE}` → Percentage (X.X%)
- `{GENERATION_TIMESTAMP}` → ISO 8601 timestamp
### Step 6: Write Report
Save the completed report to:
```
docs/releases/in_progress/{RELEASE_ID}/release_report.md
```
### Step 7: Verify
Ensure:
- All placeholders are replaced (no `{PLACEHOLDER}` tokens remain)
- All sections are populated
- **Section 9 (Testing Guidance) exists and includes all manual test cases from `integration_tests.md`**
  (REQUIRED - see `.cursor/rules/post_build_testing.md`)
- Metrics are calculated correctly
- Formatting matches template structure
**CRITICAL CHECK:** Verify Section 9 contains:
- All tests from `integration_tests.md` (IT-001 through IT-XXX)
- Each test formatted as user-facing instructions
- Step-by-step actions (not technical commands)
- Expected results for each test
- Manual validation requirements (if present in `integration_tests.md` Section 5)
## Example: Generating Report for v0.1.0

1. **Load template:** `docs/feature_units/standards/release_report_template.md`

2. **Parse status:** `docs/releases/in_progress/v0.1.0/status.md`
   - Extract: 14 batches, 27 FUs, 4 checkpoints, 11 tests, 3 decisions

3. **Parse integration tests:** `docs/releases/in_progress/v0.1.0/integration_tests.md`
   - Extract: All 11 test definitions (IT-001 through IT-011)
   - Extract: Goals, steps, expected results
   - Convert steps to user-facing actions

4. **Calculate:**
   - `batchCompletion` = (14/14) \* 100 = 100.0%
   - `fuCompletion` = (26/27) \* 100 = 96.3%
   - etc.

5. **Format sections:**
   - Generate batch rows, FU rows, checkpoint items, test table, etc.
   - **Generate Section 9 (Testing Guidance) with all 11 manual test cases** (REQUIRED)

6. **Replace placeholders** in template

7. **Verify Section 9 exists and includes all tests** (CRITICAL CHECK)

8. **Write:** `docs/releases/in_progress/v0.1.0/release_report.md`

9. **Present to user:** "Release build complete. See release_report.md Section 9 (Testing Guidance) for
   manual test cases to validate functionality."
## Integration with Release Orchestrator

The release orchestrator will:

1. Complete all batches
2. Log that report generation is required
3. Reference this guide for instructions
4. Agents/humans follow this guide to generate the report
## Troubleshooting

**Missing placeholders:** Ensure all placeholders from template are replaced

**Incorrect metrics:** Verify calculation rules in `release_report_spec.md` Section 3

**Missing sections:** Check that all data sources are parsed correctly

**Formatting issues:** Verify formatting rules in `release_report_spec.md` Section 6.3
